"""
è¿è¡Œæ‰€æœ‰ 4 ç§ masking æ¨¡å¼çš„è¯„ä¼°è„šæœ¬
ç”Ÿæˆ: bps summary + single-neuron viz plots
"""
import sys
import os
import numpy as np

# è®¾ç½®å·¥ä½œç›®å½•
work_dir = '/home/jqh/Workspace/IBL foundation model/MtM'
os.chdir(work_dir)
print('='*60)
print('å·¥ä½œç›®å½•:', work_dir)
print('='*60)

# æ·»åŠ  src è·¯å¾„
sys.path.append(os.path.join(work_dir, 'src'))

from src.utils.eval_utils import load_model_data_local, co_smoothing_eval

# ========================
# 1. é…ç½®å‚æ•°
# ========================

model_path = 'results/train/num_session_1/model_NDT1/method_ssl/mask_all/stitch_True/model_best.pt'
dataset_path = 'data/4b00df29-3769-43be-bb40-128b1cba6d35_aligned'

configs = {
    'model_config': 'src/configs/ndt1.yaml',
    'model_path': model_path,
    'trainer_config': 'src/configs/ssl_session_trainer.yaml',
    'dataset_path': dataset_path,
    'seed': 42,
}

# ========================
# 2. åŠ è½½æ¨¡å‹å’Œæ•°æ®
# ========================
print("\næ­£åœ¨åŠ è½½æ¨¡å‹å’Œæ•°æ®...")
model, accelerator, dataset, dataloader = load_model_data_local(**configs)

# æŸ¥çœ‹æ•°æ®é›†ä¿¡æ¯
print(f"\næ•°æ®é›†ä¿¡æ¯:")
print(f"  - Trial æ•°é‡: {len(dataset)}")
print(f"  - ç¥ç»å…ƒæ•°é‡: {len(dataset['cluster_regions'][0])}")
print(f"  - æ•°æ®é›†åˆ—å: {dataset.column_names}")

# è°ƒè¯•ï¼šæ£€æŸ¥ behavior å˜é‡çš„å®é™…å€¼
print(f"\nè°ƒè¯• - Behavior å˜é‡å€¼:")
choice_vals = np.array(dataset['choice'])
reward_vals = np.array(dataset['reward'])
block_vals = np.array(dataset['block'])
print(f"  - choice å”¯ä¸€å€¼: {np.unique(choice_vals)}")
print(f"  - reward å”¯ä¸€å€¼: {np.unique(reward_vals)}")
print(f"  - block å”¯ä¸€å€¼: {np.unique(block_vals)}")

# è·å–è„‘åŒºä¿¡æ¯
regions = list(set(dataset['cluster_regions'][0]))
print(f"  - è„‘åŒºæ•°é‡: {len(regions)}")
print(f"  - è„‘åŒºåˆ—è¡¨: {regions[:5]}..." if len(regions) > 5 else f"  - è„‘åŒºåˆ—è¡¨: {regions}")

# ç¡®å®šæ—¶é—´æ­¥æ•°ï¼ˆä» session_metadata æˆ– dataloader æ¨æ–­ï¼‰
n_time_steps = 60  # é»˜è®¤å€¼ï¼Œä»é…ç½®æ–‡ä»¶è·å–
print(f"  - æ—¶é—´æ­¥æ•°: {n_time_steps}")

# ========================
# 3. å®šä¹‰è¯„ä¼°ä»»åŠ¡
# ========================

tasks = {
    'co-smooth': {
        'mode': 'per_neuron',
        'target_regions': None,
        'held_out_list': None,
        'description': 'N-1 é¢„æµ‹: mask ä¸€ä¸ªç¥ç»å…ƒï¼Œé¢„æµ‹å…¶ä½™ç¥ç»å…ƒ',
    },
    'causal': {
        'mode': 'forward_pred',
        'target_regions': None,
        'held_out_list': list(range(n_time_steps // 2, n_time_steps)),  # é¢„æµ‹ååŠæ®µ
        'description': 'å› æœé¢„æµ‹: ä½¿ç”¨å†å²æ—¶é—´æ­¥é¢„æµ‹æœªæ¥æ—¶é—´æ­¥',
    },
    'inter-region': {
        'mode': 'inter_region',
        'target_regions': ['all'],
        'held_out_list': None,
        'description': 'è·¨è„‘åŒº: mask ä¸€ä¸ªè„‘åŒºï¼Œé¢„æµ‹è¯¥è„‘åŒºç¥ç»å…ƒ',
    },
    'intra-region': {
        'mode': 'intra_region',
        'target_regions': ['all'],
        'held_out_list': None,
        'description': 'åŒºåŸŸå†…: mask å…¶ä»–è„‘åŒºï¼Œé¢„æµ‹ç›®æ ‡è„‘åŒºç¥ç»å…ƒ',
    },
}

# ========================
# 4. è¿è¡Œè¯„ä¼°
# ========================

results_summary = {}

for task_name, task_config in tasks.items():
    print(f"\n{'='*60}")
    print(f"ä»»åŠ¡: {task_name}")
    print(f"æè¿°: {task_config['description']}")
    print('='*60)

    save_path = f'figs/eval/{task_name}'

    eval_configs = {
        'subtract': 'task',
        'onset_alignment': [n_time_steps // 3],  # çº¦ 1/3 ä½ç½®ä½œä¸ºå¯¹é½ç‚¹
        'method_name': task_name,
        'save_path': save_path,
        'mode': task_config['mode'],
        'n_time_steps': n_time_steps,
        'is_aligned': True,
        'target_regions': task_config['target_regions'],
        'held_out_list': task_config['held_out_list'],
        'n_jobs': 8,
    }

    # è¿è¡Œè¯„ä¼°
    try:
        result = co_smoothing_eval(model, accelerator, dataloader, dataset, **eval_configs)
        results_summary[task_name] = result
        print(f"\nâœ… {task_name} è¯„ä¼°å®Œæˆ!")
        print(f"   è¾“å‡ºç›®å½•: {save_path}")
    except Exception as e:
        print(f"\nâŒ {task_name} è¯„ä¼°å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        results_summary[task_name] = None

# ========================
# 5. æ‰“å°æ±‡æ€»ç»“æœ
# ========================

print("\n" + "="*60)
print("è¯„ä¼°ç»“æœæ±‡æ€»")
print("="*60)

for task_name, result in results_summary.items():
    print(f"\nğŸ“Š {task_name}:")
    if result:
        mode_key = tasks[task_name]['mode']
        print(f"   Mean BPS: {result.get(f'{mode_key}_mean_bps', 'N/A'):.4f}")
        print(f"   Std BPS:  {result.get(f'{mode_key}_std_bps', 'N/A'):.4f}")
        print(f"   Mean RÂ² (PSTH): {result.get(f'{mode_key}_mean_r2_psth', 'N/A'):.4f}")
        print(f"   Mean RÂ² (Trial): {result.get(f'{mode_key}_mean_r2_trial', 'N/A'):.4f}")
    else:
        print("   è¯„ä¼°å¤±è´¥")

print("\n" + "="*60)
print("æ‰€æœ‰ä»»åŠ¡å®Œæˆ!")
print("="*60)
print(f"\nå›¾è¡¨ä¿å­˜åœ¨: {os.path.join(work_dir, 'figs/eval/')}")
